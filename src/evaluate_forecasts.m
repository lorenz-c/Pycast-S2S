function [] = evaluate_forecasts(domain, month, year, version)

vars = {'tp', 't2m', 't2min', 't2max', 'ssrd'};

vars = {'tp', 't2m'};

yr_str   = num2str(year);
mnth_str = num2str(month, '%02.0f');

if year < 2017
    ens = 25;
else
    ens = 51;
end

if strcmp(domain, 'Khuzestan')
    basin_name = 'khuzestan';
    basin_id   = '1000000';
elseif strcmp(domain, 'SF_Basin')
    basin_name = 'sf_basin';
    basin_id   = '2000000';
elseif strcmp(domain, 'TABN')
    basin_name = 'tabn';
    basin_id   = '3000000';
elseif strcmp(domain, 'Chira')
    basin_name = 'chira';
    basin_id   = '4000000';
end


% Set the base-directory for the current domain
basedir = ['/pd/data/regclim_data/gridded_data/processed/', domain];
dirout  = ['/pd/data/regclim_data/sawam_output/', basin_name, '/frcst/raster/hydromet/'];

climatology      = [basedir, '/climatology/era5_land/ERA5_Land_climatology_1981_2016_', domain, '.nc'];
tercile_ref_fle  = [basedir, '/monthly/seas5_bcsd_thresholds/SEAS5_BCSD_v', version, '_monthly_terciles_', mnth_str, '_0.1_', domain, '.nc'];
quintile_ref_fle = [basedir, '/monthly/seas5_bcsd_thresholds/SEAS5_BCSD_v', version, '_monthly_quintiles_', mnth_str, '_0.1_', domain, '.nc'];
extreme_ref_fle  = [basedir, '/monthly/seas5_bcsd_thresholds/SEAS5_BCSD_v', version, '_monthly_extreme_quantiles_', mnth_str, '_0.1_', domain, '.nc'];

% Set the filename of the current forecast
fle_in  = [basedir, '/monthly/seas5_bcsd/SEAS5_BCSD_v', version, '_monthly_', yr_str, mnth_str, '_0.1_', domain, '.nc'];

% Get the time of the forecast in the current directory
tme      = ncread(fle_in, 'time');
tme_unit = ncreadatt(fle_in, 'time', 'units');
tme_abs  = reldate2absdate(tme, tme_unit);

tme_abs(:, 3)     = 15;
tme_abs(:, 4:end) = 0;

tme_out      = days(datetime(tme_abs) - datetime('1980-01-01 00:00:00'));
tme_unit_out = 'days since 1980-01-01 00:00:00';

issue_date = [yr_str, mnth_str, '01'];

% Get the latitudes and longitudes
lat      = ncread(fle_in, 'lat');
lon      = ncread(fle_in, 'lon');

% Calculate the lenghts of the dimensions
nlat    = length(lat);
nlon    = length(lon);

[fleinfo, varinfo] = set_metadata(vars);
    
fle_out = [dirout, basin_id, '_frcst_raster_hydromet_monthly_multiple_kit_seas5bcsd_v', version, '_e1_', yr_str, mnth_str, '15.nc'];
       
create_3d_netcdf(fle_out, ...
                 fleinfo, ...
                 varinfo.short, ...
                 varinfo.standard, ...
                 varinfo.long, ...
                 varinfo.units, ...
                 varinfo.precision, ...
                 varinfo.fill, ...
                 varinfo.scale, ...
                 varinfo.offset, ...
                 tme_out, ...
                 lat, ...
                 lon, ...
                 tme_unit_out, ...
                 true, ...
                 [length(lon) length(lat) 1], ...
                 true)   

% Add the issue date to the output file
ncwriteatt(fle_out, '/', 'issue_date', issue_date)
    
for i = 1:length(vars)
    
    dta_in       = ncread(fle_in, vars{i});
    dta_in       = dta_in(:, :, :, 1:7);

    tercile_ref  = ncread(tercile_ref_fle, vars{i});
    quintile_ref = ncread(quintile_ref_fle, vars{i});
    extreme_ref  = ncread(extreme_ref_fle, vars{i});
    
    clim         = ncread(climatology, vars{i});
    clim         = clim(:, :, tme_abs(1:7, 2));
    
    % Compute the ensemble mean, ...
    ens_mean     = squeeze(mean(dta_in, 3));
    % ...ensemble median, ...
    ens_median   = squeeze(median(dta_in, 3));
    % ...ensemble standard deviation, ...
    ens_std      = squeeze(std(dta_in, [], 3));
    % ...ensemble inter quantile range, ...
    ens_iqr      = squeeze(iqr(dta_in, 3));
    % ...ensemble spread, ...
    ens_spread   = squeeze(max(dta_in, [], 3) - min(dta_in, [], 3));
    % ...the deviation of the ensemble mean from the climatology, ...
    delta_clim   = ens_mean - clim;
    % ...the mean relative anomaly, ...
    ens_mean_rel = (ens_mean ./ clim - 1) * 100;
    % ...and the median relative anomaly
    ens_med_rel  = (ens_median ./ clim - 1) * 100;
    
    terciles_sum  = NaN(length(lon), length(lat), 3, size(dta_in, 4));
    quintiles_sum = NaN(length(lon), length(lat), 5, size(dta_in, 4));
    extreme_sum   = NaN(length(lon), length(lat), 2, size(dta_in, 4));
    
    mask = NaN(size(dta_in, 1), size(dta_in, 2));
    mask(~isnan(dta_in(:, :, 1, 1))) = 1;
         
    for j = 1:size(dta_in, 4)
        
        % Count the number of ensemble members for each tercile category
        terciles_sum(:, :, 1, j) = sum(dta_in(:, :, :, j) < tercile_ref(:, :, 1, j), 3);
        terciles_sum(:, :, 2, j) = sum(dta_in(:, :, :, j) >= tercile_ref(:, :, 1, j) & dta_in(:, :, :, j) < tercile_ref(:, :, 2, j), 3);
        terciles_sum(:, :, 3, j) = sum(dta_in(:, :, :, j) >= tercile_ref(:, :, 2, j), 3);
    
        % Count the number of ensemble members for each quintile category
        quintiles_sum(:, :, 1, j) = sum(dta_in(:, :, :, j) <  quintile_ref(:, :, 1, j), 3);
        quintiles_sum(:, :, 2, j) = sum(dta_in(:, :, :, j) >= quintile_ref(:, :, 1, j) & dta_in(:, :, :, j) < quintile_ref(:, :, 2, j), 3);
        quintiles_sum(:, :, 3, j) = sum(dta_in(:, :, :, j) >= quintile_ref(:, :, 2, j) & dta_in(:, :, :, j) < quintile_ref(:, :, 3, j), 3);
        quintiles_sum(:, :, 4, j) = sum(dta_in(:, :, :, j) >= quintile_ref(:, :, 3, j) & dta_in(:, :, :, j) < quintile_ref(:, :, 4, j), 3);
        quintiles_sum(:, :, 5, j) = sum(dta_in(:, :, :, j) >= quintile_ref(:, :, 4, j), 3);
    
        % Count the number of ensemble members for each extreme category
        extreme_sum(:, :, 1, j) = sum(dta_in(:, :, :, j) < extreme_ref(:, :, 1, j), 3);
        extreme_sum(:, :, 2, j) = sum(dta_in(:, :, :, j) > extreme_ref(:, :, 2, j), 3);  
    
    end
    
    terciles_sum  = terciles_sum / ens * 100 .* repmat(mask, 1, 1, 3, size(dta_in, 4));
    quintiles_sum = quintiles_sum / ens * 100 .* repmat(mask, 1, 1, 5, size(dta_in, 4));
    extreme_sum   = extreme_sum / ens * 100 .* repmat(mask, 1, 1, 2, size(dta_in, 4));
    
    
    % Get the categories with the most ensemble members
    % Here, Y holds the probability of a category and I the index of that
    % category
    [Y_quintiles, I_quintiles] = max(quintiles_sum,[],3);
    [Y_terciles, I_terciles]   = max(terciles_sum,[],3);
    [Y_extreme, I_extreme]     = max(extreme_sum,[],3);
    
    Y_quintiles = squeeze(Y_quintiles);
    I_quintiles = squeeze(I_quintiles);
    Y_terciles  = squeeze(Y_terciles);
    I_terciles  = squeeze(I_terciles);
    Y_extreme   = squeeze(Y_extreme);
    I_extreme   = squeeze(I_extreme);

    % In cases where all ensemble member fall in the same category, set the probability to 99.9% so that we do not "jump" into the next category´
    Y_quintiles(Y_quintiles == 100) = 99.99;
    Y_terciles(Y_terciles == 100)   = 99.99;
    Y_extreme(Y_extreme == 100)     = 99.99;
    
    % Construct a new variable which holds the category and the
    % corresponding probability
    max_categ_quintiles = I_quintiles + Y_quintiles/100;
    max_categ_terciles  = I_terciles + Y_terciles/100;
    max_categ_extreme   = I_extreme + Y_extreme/100;
    
    % In cases where the probability of the maximum category "less than low", set these pixels to -0.5; this is in accordance with the approach from SMHI; see 
    % https://hypewebapp.smhi.se/hypeweb-climate/seasonal-forecasts/metadata/Glorious_SeFo_Metadata_RiverFlow.pdf
    max_categ_quintiles(Y_quintiles == 25) = 0.5;
    max_categ_terciles(Y_terciles == 35)   = 0.5;
    
    % For precipitation forecasts, set all pixels with less than 1mm/day to -0.5
    if strcmp(vars{i}, 'tp')
        max_categ_quintiles(squeeze(extreme_ref(:, :, 2, :)) < 1) = -0.5;
        max_categ_terciles(squeeze(extreme_ref(:, :, 2, :)) < 1) = -0.5;
        max_categ_extreme(squeeze(extreme_ref(:, :, 2, :)) < 1) = -0.5;
    end


    % For all the temperature data, transform values from °K to °C
    if strcmp(vars{i}, 't2m') | strcmp(vars{i}, 't2min') | strcmp(vars{i}, 't2max')
        ens_mean = ens_mean - 273.15;
        ens_median = ens_median - 273.15;
    end

    % Round most of the variables to one digit
    if strcmp(vars{i}, 'tp') | strcmp(vars{i}, 't2m') | strcmp(vars{i}, 't2min') | strcmp(vars{i}, 't2max') | strcmp(vars{i}, 'ssrd')
        ens_mean     = round(ens_mean, 1);
        ens_median   = round(ens_median, 1);
        ens_spread   = round(ens_spread, 1);
        ens_std      = round(ens_std, 1);
        ens_iqr      = round(ens_iqr, 1);
        delta_clim   = round(delta_clim, 1);
        ens_mean_rel = round(ens_mean_rel, 1);

        max_categ_terciles  = round(max_categ_terciles, 2);
        max_categ_quintiles = round(max_categ_quintiles, 2);
        max_categ_extreme  = round(max_categ_extreme, 2);

        terciles_sum = round(terciles_sum, 1);
        extreme_sum  = round(extreme_sum, 1);
    end


    ncwrite(fle_out, [vars{i}, '_ensemble_mean'], ens_mean);
    ncwrite(fle_out, [vars{i}, '_ensemble_median'], ens_median);
    ncwrite(fle_out, [vars{i}, '_ensemble_spread'], ens_spread);
    ncwrite(fle_out, [vars{i}, '_ensemble_std'], ens_std);
    ncwrite(fle_out, [vars{i}, '_ensemble_iqr'], ens_iqr);
    ncwrite(fle_out, [vars{i}, '_ensemble_anomaly'], delta_clim);
    ncwrite(fle_out, [vars{i}, '_ensemble_mean_relative'], ens_mean_rel);
    ncwrite(fle_out, [vars{i}, '_tercile_probab'], max_categ_terciles);
    ncwrite(fle_out, [vars{i}, '_quintile_probab'], max_categ_quintiles);
    ncwrite(fle_out, [vars{i}, '_extreme_probab'], max_categ_extreme);
    
    ncwrite(fle_out, [vars{i}, '_above_normal_probab'], squeeze(terciles_sum(:, :, 3, :)));
    ncwrite(fle_out, [vars{i}, '_below_normal_probab'], squeeze(terciles_sum(:, :, 1, :)));
    ncwrite(fle_out, [vars{i}, '_extreme_high_probab'], squeeze(extreme_sum(:, :, 2, :)));
    ncwrite(fle_out, [vars{i}, '_extreme_low_probab'], squeeze(extreme_sum(:, :, 1, :)));
    
end
           
end


% 
function [fleinfo, varinfo] = set_metadata(variable)

% Set the global attributes
fleinfo.title          = 'SEAS5 BCSD v2.1, probabilistic forecasts and forecast measures';
fleinfo.Conventions    = 'CF-1.8';
fleinfo.references     = 'TBA';
fleinfo.institution    = 'Karlsruhe Institute of Technology - Institute of Meteorology and Climate Research';
fleinfo.source         = 'ECMWF SEAS5, ERA5-Land';
fleinfo.comment        = '';
fleinfo.history        = [datestr(now, 'yyyy-mm-dd HH:MM:SS'), ': File created.'];
fleinfo.Contact_person = 'Christof Lorenz (Christof.Lorenz@kit.edu)';
fleinfo.Author         = 'Christof Lorenz (Christof.Lorenz@kit.edu)';
fleinfo.License        = 'For non-commercial use only';


varinfo = struct('short', [], ...
                 'long', [], ...
                 'standard', [], ...
                 'units', [], ...
                 'precision', [], ...
                 'fill', [], ...
                 'scale', [], ...
                 'offset', []);


for i = 1:length(variable)
    
    varinfo.short = [varinfo.short, ...
                     {[variable{i}, '_ensemble_mean'], ...
                      [variable{i}, '_ensemble_median'], ...
                      [variable{i}, '_ensemble_spread'], ...
                      [variable{i}, '_ensemble_std'], ...
                      [variable{i}, '_ensemble_iqr'], ...
                      [variable{i}, '_ensemble_anomaly'], ...
                      [variable{i}, '_ensemble_mean_relative'], ...
                      [variable{i}, '_tercile_probab'], ...
                      [variable{i}, '_quintile_probab'], ...
                      [variable{i}, '_extreme_probab'], ...
                      [variable{i}, '_above_normal_probab'], ...
                      [variable{i}, '_below_normal_probab'], ...
                      [variable{i}, '_extreme_high_probab'], ...
                      [variable{i}, '_extreme_low_probab']}];

    varinfo.long  = [varinfo.long, ...
                    {'Ensemble mean', ...
                     'Ensemble median', ...
                     'Ensemble spread', ...
                     'Ensemble standard deviation', ...
                     'Ensemble inter quartile range', ...
                     'Ensemble anomaly from the climatology', ...
                     'Relative ensemble anomaly', ...
                     'Tercile category and probability with most ensemble members', ...
                     'Quintile category and probability with most ensemble members', ...
                     'Extreme category and probability with most ensemble members', ...
                     'Probability of above normal conditions', ...
                     'Probability of below normal conditions', ...
                     'Probability of extreme high conditions', ...
                     'Probability of extreme low conditions'}];
             
    varinfo.standard  = [varinfo.standard, ...
                        {[], ...
                         [], ...
                         [], ...
                         [], ...
                         [], ...
                         [], ...
                         []', ...
                         []', ...
                         [], ...
                         [], ...
                         []', ...
                         []', ...
                         []', ...
                         []}];

    if strcmp(variable{i}, 'tp')
        varinfo.units  = [varinfo.units, ...
                         {'mm/day', ...
                          'mm/day', ...
                          'mm/day', ...
                          'mm/day', ...
                          'mm/day', ...
                          'mm/day', ...
                          [], ...
                          [], ...
                          [], ...
                          [], ...
                          '%', ...
                          '%', ...
                          '%', ...
                          '%'}];
                      
    elseif strcmp(variable{i}, 't2m') | strcmp(variable{i}, 't2min') | strcmp(variable{i}, 't2max')
        varinfo.units  = [varinfo.units, ...
                         {'°C', ...
                          '°C', ...
                          '°C', ...
                          '°C', ...
                          '°C', ...
                          '°C', ...
                          [], ...
                          [], ...
                          [], ...
                          [], ...
                          '%', ...
                          '%', ...
                          '%', ...
                          '%'}];
                      
    elseif strcmp(variable{i}, 'ssrd')
        varinfo.units  = [varinfo.units, ...
                         {'W m-2', ...
                          'W m-2', ...
                          'W m-2', ...
                          'W m-2', ...
                          'W m-2', ...
                          'W m-2', ...
                          [], ...
                          [], ...
                          [], ...
                          [], ...
                          '%', ...
                          '%', ...
                          '%', ...
                          '%'}];
                      
    end

    varinfo.precision  = [varinfo.precision, ...
                         {'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT', ...
                          'NC_FLOAT'}];

                 
    varinfo.fill       = [varinfo.fill, ...
                             {-9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999, ...
                              -9999}];
                          
    varinfo.scale          = [varinfo.scale, ...
                             {[], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              []}];
                          
    varinfo.offset         = [varinfo.offset, ...
                             {[], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              [], ...
                              []}];
                          
end



end
